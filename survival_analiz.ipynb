{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kutayalptekinn/AI-Projects/blob/main/survival_analiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfAkvHeGUHTG"
      },
      "source": [
        "##ANALİZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh7vvFq1UECQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import VGG19               # VGG19\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50         # ResNet50\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet       # MobileNet\n",
        "from tensorflow.keras.applications.densenet import DenseNet169      # DenseNet169\n",
        "from tensorflow.keras.applications import EfficientNetB0            # EfficientNetB0\n",
        "from tensorflow.keras.applications import InceptionV3               # ınceprionV3\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import csv\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Udxxx4UhPu",
        "outputId": "f84f2268-c89e-4f19-b5e9-05fcf2901f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4u0suZcUhR_"
      },
      "outputs": [],
      "source": [
        "img_width, img_height = 256,357 #width & height of input image\n",
        "input_depth = 3 #1: gray image\n",
        "Dataset_Analiz_dir = '/content/drive/MyDrive/Dataset_Analiz'\n",
        "batchSize = 10 #training batch size\n",
        "batch_size = 10\n",
        "data_dir = pathlib.Path(Dataset_Analiz_dir) # SELECT DATASET SOURCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z47e_fi9UPPa"
      },
      "source": [
        "##DATASET HAZIRLAMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx8jd_N_UQb1"
      },
      "outputs": [],
      "source": [
        "# Veri klasörlerinin yollarını belirleme\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "# Hasta insanların klasörlerinin yollarını belirleme\n",
        "sick_dir = os.path.join(data_dir, 'patient')\n",
        "\n",
        "# Tüm hastaları ve sağlıklı insanları bir listeye yerleştirme\n",
        "sick_people = [os.path.join(sick_dir, f) for f in os.listdir(sick_dir)]\n",
        "#random dağıt\n",
        "random.shuffle(sick_people)\n",
        "\n",
        "# Train, test ve val bölümlerini ayırma\n",
        "train_people = sick_people[:90]\n",
        "val_people = sick_people[90:124]\n",
        "test_people = sick_people[124:148]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wi79oKMnV1m"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# CSV dosyaları oluşturma\n",
        "def create_csv(file_name, people_list):\n",
        "    with open(file_name, mode='w', newline='') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"img\", \"status\"])\n",
        "        for person in people_list:\n",
        "              for imgs in os.listdir(person):\n",
        "\n",
        "                  if \"horizontal\" in imgs:\n",
        "                      last_part = imgs.split(\"_\")[1]\n",
        "                  else:\n",
        "                      last_part = person.split(\"_\")[-1]\n",
        "\n",
        "                  # Remove any non-digit characters from the last part\n",
        "                  number = \"\".join(filter(str.isdigit, last_part))\n",
        "                  number = int(number)\n",
        "\n",
        "                  if number > 0 and number <= 360:\n",
        "                      label = 0\n",
        "                  elif number > 360 and number <= 720:\n",
        "                      label = 1\n",
        "                  elif number > 720 and number <= 1800:\n",
        "                      label = 2\n",
        "\n",
        "                  # Write original image path and label\n",
        "                  writer.writerow([person+\"/\"+imgs, label])\n",
        "\n",
        "                  ## Aşağıdaki 16 satırlık işlemler 1 kereliğine verisetini arttırmak amacıyla uygulanıp yorum satırına alınır\n",
        "                  # Apply horizontal flip to the image\n",
        "                  img = Image.open(person+\"/\"+imgs)\n",
        "                  img_horizontal = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                  output_directory = os.path.join(data_dir, \"train\", person+\"_horizontal\")\n",
        "                  os.makedirs(output_directory, exist_ok=True)\n",
        "                  # Generate new filename for the horizontal flipped image\n",
        "                  img_filename = os.path.splitext(imgs)[0]  # Dosya adını alın\n",
        "                  img_extension = os.path.splitext(imgs)[1]  # Dosya uzantısını alın\n",
        "                  img_horizontal_filename = f\"{img_filename}_horizontal{img_extension}\"\n",
        "                  img_horizontal_path = os.path.join(output_directory, img_horizontal_filename)\n",
        "\n",
        "                  # Save the horizontal flipped image\n",
        "                  img_horizontal.save(img_horizontal_path)\n",
        "                  # Write horizontal flipped image path and label\n",
        "                  writer.writerow([os.path.join(person, img_horizontal_filename), label])\n",
        "                  ##\n",
        "\n",
        "try:\n",
        "  os.makedirs(os.path.join(data_dir,\"/train\"))\n",
        "  os.makedirs(os.path.join(data_dir,\"/test\"))\n",
        "  os.makedirs(os.path.join(data_dir,\"/val\"))\n",
        "  # os.makedirs(data_dir+\"/train\")\n",
        "  # os.makedirs(data_dir+\"/test\")\n",
        "  # os.makedirs(data_dir+\"/val\")\n",
        "except OSError:\n",
        "  pass\n",
        "\n",
        "create_csv(os.path.join(train_dir, 'train.csv'), train_people)\n",
        "create_csv(os.path.join(test_dir, 'test.csv'), test_people)\n",
        "create_csv(os.path.join(val_dir, 'val.csv'), val_people)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngSie6MTnV31"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(os.path.join(train_dir,'train.csv'))\n",
        "val_df = pd.read_csv(os.path.join(val_dir,'val.csv'))\n",
        "test_df = pd.read_csv(os.path.join(test_dir,'test.csv'))\n",
        "\n",
        "train_labels = to_categorical(train_df['status'])\n",
        "val_labels = to_categorical(val_df['status'])\n",
        "test_labels = to_categorical(test_df['status'])\n",
        "\n",
        "train_df['status'] = train_df['status'].astype(str)\n",
        "val_df['status'] = val_df['status'].astype(str)\n",
        "test_df['status'] = test_df['status'].astype(str)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    shear_range=0.2,  # Kesme dönüşümü\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)  # Rastgele yakınlaştırma\n",
        "val_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXi-qE2jnWAR",
        "outputId": "654545a1-e819-4a6d-dc83-db990131521a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 900 validated image filenames belonging to 3 classes.\n",
            "Found 340 validated image filenames belonging to 3 classes.\n",
            "Found 240 validated image filenames belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col=\"img\", y_col=\"status\", color_mode='rgb',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col=\"img\", y_col=\"status\", color_mode='rgb',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col=\"img\", y_col=\"status\", color_mode='rgb',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batchSize,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=123\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEXwNah4nWCf"
      },
      "outputs": [],
      "source": [
        "train_ds = train_generator\n",
        "\n",
        "val_ds = val_generator\n",
        "\n",
        "test_ds = test_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2DjXYswUPhx"
      },
      "source": [
        "##MODEL EĞİTİMİ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id1ETqukw5gH"
      },
      "source": [
        "# Costum model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcXKPoIdwrRq"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_width, img_height, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(3,activation='softmax')\n",
        "])\n",
        "\n",
        "# Freeze the layers before the last convolutional layer\n",
        "# for layer in model.layers[:-6]:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# base_model = VGG19(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# # VGG19 modelinin üzerine eklenen katmanlar\n",
        "# model = models.Sequential()\n",
        "# model.add(base_model)\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(256, activation='relu'))\n",
        "# model.add(layers.Dropout(0.5))\n",
        "# model.add(layers.Dense(128, activation='relu'))\n",
        "# model.add(layers.Dense(3, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO1XbYGgxVhL"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-2yKzKExVj4"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, min_delta=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZyWZBcgxVmb",
        "outputId": "05928de8-b473-4375-8382-1829b8eb7442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "90/90 [==============================] - 103s 1s/step - loss: 1.3615 - accuracy: 0.5122 - val_loss: 1.0919 - val_accuracy: 0.3735\n",
            "Epoch 2/50\n",
            "90/90 [==============================] - 108s 1s/step - loss: 0.8773 - accuracy: 0.6000 - val_loss: 1.0468 - val_accuracy: 0.5912\n",
            "Epoch 3/50\n",
            "90/90 [==============================] - 106s 1s/step - loss: 0.6951 - accuracy: 0.6733 - val_loss: 1.0526 - val_accuracy: 0.6029\n",
            "Epoch 4/50\n",
            "90/90 [==============================] - 105s 1s/step - loss: 0.5856 - accuracy: 0.7489 - val_loss: 1.0248 - val_accuracy: 0.6500\n",
            "Epoch 5/50\n",
            "90/90 [==============================] - 106s 1s/step - loss: 0.4956 - accuracy: 0.7944 - val_loss: 0.8287 - val_accuracy: 0.6676\n",
            "Epoch 6/50\n",
            "90/90 [==============================] - 105s 1s/step - loss: 0.4856 - accuracy: 0.8022 - val_loss: 1.0020 - val_accuracy: 0.5853\n",
            "Epoch 7/50\n",
            "90/90 [==============================] - 104s 1s/step - loss: 0.4054 - accuracy: 0.8467 - val_loss: 1.1384 - val_accuracy: 0.6471\n",
            "Epoch 8/50\n",
            "90/90 [==============================] - 107s 1s/step - loss: 0.3453 - accuracy: 0.8578 - val_loss: 0.8509 - val_accuracy: 0.7000\n",
            "Epoch 9/50\n",
            "90/90 [==============================] - 102s 1s/step - loss: 0.2830 - accuracy: 0.8944 - val_loss: 0.8689 - val_accuracy: 0.7118\n",
            "Epoch 10/50\n",
            "90/90 [==============================] - 106s 1s/step - loss: 0.3016 - accuracy: 0.8733 - val_loss: 0.9711 - val_accuracy: 0.7118\n",
            "Epoch 11/50\n",
            "90/90 [==============================] - 105s 1s/step - loss: 0.2364 - accuracy: 0.9122 - val_loss: 1.1564 - val_accuracy: 0.7441\n",
            "Epoch 12/50\n",
            "90/90 [==============================] - 104s 1s/step - loss: 0.1950 - accuracy: 0.9278 - val_loss: 1.1309 - val_accuracy: 0.7588\n",
            "Epoch 13/50\n",
            "90/90 [==============================] - 106s 1s/step - loss: 0.2137 - accuracy: 0.9144 - val_loss: 1.1257 - val_accuracy: 0.7647\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  callbacks=callback\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeTy1f2ixVrA",
        "outputId": "fe5e5942-87f6-4f36-8964-62108d84fb63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 11s 477ms/step - loss: 1.5167 - accuracy: 0.7083\n",
            "Test Loss: 1.5166971683502197\n",
            "Test Accuracy: 0.7083333134651184\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yyy_EOB0p9L"
      },
      "source": [
        "#VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uhAeFeC0rmt",
        "outputId": "5b640ff5-1a4b-46ca-c404-fe88d6133a57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 2s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 357, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 256, 357, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 256, 357, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 128, 178, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 128, 178, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 128, 178, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 64, 89, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 64, 89, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 64, 89, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 64, 89, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 64, 89, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 32, 44, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 32, 44, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 32, 44, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 32, 44, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 32, 44, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 16, 22, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 16, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 16, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 16, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 16, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 8, 11, 512)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 45056)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               5767296   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,792,067\n",
            "Trainable params: 5,767,683\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# VGG19 modeli\n",
        "base_model = VGG19(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = layers.Flatten()(base_model.output)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(base_model.input, x)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Msg9-NO409R1"
      },
      "outputs": [],
      "source": [
        "# Modeli derleme ve eğitim\n",
        "#model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy(from_logits=True), metrics=['accuracy'])\n",
        "#model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=20,min_delta=0,\n",
        "                                            restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C6VNGB9d1B2p",
        "outputId": "21ecd4bc-2114-4608-838a-36d1200f31ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90\n",
            "34\n",
            "Epoch 1/100\n",
            "90/90 [==============================] - 1187s 13s/step - loss: 4.5993 - accuracy: 0.7556 - val_loss: 3.4442 - val_accuracy: 0.7559\n",
            "Epoch 2/100\n",
            "90/90 [==============================] - 1186s 13s/step - loss: 0.6452 - accuracy: 0.9211 - val_loss: 2.0560 - val_accuracy: 0.7588\n",
            "Epoch 3/100\n",
            "90/90 [==============================] - 1189s 13s/step - loss: 0.4784 - accuracy: 0.9367 - val_loss: 2.2225 - val_accuracy: 0.7853\n",
            "Epoch 4/100\n",
            "90/90 [==============================] - 1185s 13s/step - loss: 0.5839 - accuracy: 0.9311 - val_loss: 1.4088 - val_accuracy: 0.8265\n",
            "Epoch 5/100\n",
            "90/90 [==============================] - 1178s 13s/step - loss: 0.2367 - accuracy: 0.9567 - val_loss: 0.8249 - val_accuracy: 0.8206\n",
            "Epoch 6/100\n",
            "90/90 [==============================] - 1183s 13s/step - loss: 0.1754 - accuracy: 0.9633 - val_loss: 1.3136 - val_accuracy: 0.7912\n",
            "Epoch 7/100\n",
            "90/90 [==============================] - 1192s 13s/step - loss: 0.0884 - accuracy: 0.9733 - val_loss: 1.7854 - val_accuracy: 0.8029\n",
            "Epoch 8/100\n",
            "90/90 [==============================] - 1181s 13s/step - loss: 0.0619 - accuracy: 0.9811 - val_loss: 1.6826 - val_accuracy: 0.7971\n",
            "Epoch 9/100\n",
            "90/90 [==============================] - 1185s 13s/step - loss: 0.1775 - accuracy: 0.9656 - val_loss: 2.1671 - val_accuracy: 0.8206\n",
            "Epoch 10/100\n",
            "90/90 [==============================] - 1186s 13s/step - loss: 0.1495 - accuracy: 0.9600 - val_loss: 1.7084 - val_accuracy: 0.8676\n",
            "Epoch 11/100\n",
            "90/90 [==============================] - 1144s 13s/step - loss: 0.0967 - accuracy: 0.9733 - val_loss: 2.1384 - val_accuracy: 0.8176\n",
            "Epoch 12/100\n",
            "90/90 [==============================] - 1148s 13s/step - loss: 0.1072 - accuracy: 0.9733 - val_loss: 1.7538 - val_accuracy: 0.8529\n",
            "Epoch 13/100\n",
            "90/90 [==============================] - 1131s 13s/step - loss: 0.1210 - accuracy: 0.9778 - val_loss: 2.0782 - val_accuracy: 0.8647\n",
            "Epoch 14/100\n",
            "90/90 [==============================] - 1147s 13s/step - loss: 0.0634 - accuracy: 0.9833 - val_loss: 2.7456 - val_accuracy: 0.8235\n",
            "Epoch 15/100\n",
            "90/90 [==============================] - 1140s 13s/step - loss: 0.2315 - accuracy: 0.9778 - val_loss: 2.7094 - val_accuracy: 0.8471\n",
            "Epoch 16/100\n",
            "90/90 [==============================] - 1143s 13s/step - loss: 0.0504 - accuracy: 0.9900 - val_loss: 2.7251 - val_accuracy: 0.8618\n",
            "Epoch 17/100\n",
            "21/90 [======>.......................] - ETA: 10:29 - loss: 0.0091 - accuracy: 0.9952"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-99114a736e75>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  callbacks=callback\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YesbAwWC1CxO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9wSJzP1SWsF"
      },
      "source": [
        "# K-Flod Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yvn-LyxlSbfq"
      },
      "outputs": [],
      "source": [
        "# Veri klasörlerinin yollarını belirleme\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "# Hasta insanların klasörlerinin yollarını belirleme\n",
        "sick_dir = os.path.join(data_dir, 'patient')\n",
        "\n",
        "# Tüm hastaları ve sağlıklı insanları bir listeye yerleştirme\n",
        "sick_people = [os.path.join(sick_dir, f) for f in os.listdir(sick_dir)]\n",
        "#random dağıt\n",
        "random.shuffle(sick_people)\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(train_dir,'train.csv'))\n",
        "val_df = pd.read_csv(os.path.join(val_dir,'val.csv'))\n",
        "test_df = pd.read_csv(os.path.join(test_dir,'test.csv'))\n",
        "\n",
        "train_labels = to_categorical(train_df['status'])\n",
        "val_labels = to_categorical(val_df['status'])\n",
        "test_labels = to_categorical(test_df['status'])\n",
        "\n",
        "train_df['status'] = train_df['status'].astype(str)\n",
        "val_df['status'] = val_df['status'].astype(str)\n",
        "test_df['status'] = test_df['status'].astype(str)\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator()\n",
        "# DataFrame'leri birleştirme\n",
        "merged_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFQ9fKPuTxmn"
      },
      "outputs": [],
      "source": [
        "Labels = train_df['status'].unique().tolist()\n",
        "\n",
        "# Store loss values\n",
        "epochsK = []\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "# Create K-fold object\n",
        "k = 5\n",
        "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Iterate over each fold\n",
        "fold_no = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OdfGeCDTyCs",
        "outputId": "20e0862b-bd19-4b12-9f1f-e242d08ea1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: \n",
            "\n",
            "Found 1184 validated image filenames belonging to 3 classes.\n",
            "Found 296 validated image filenames belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 2s 0us/step\n",
            "Epoch 1/50\n",
            "119/119 [==============================] - 2408s 20s/step - loss: 4.5777 - accuracy: 0.7762 - val_loss: 0.3339 - val_accuracy: 0.9257\n",
            "Epoch 2/50\n",
            "119/119 [==============================] - 2416s 20s/step - loss: 0.1799 - accuracy: 0.9603 - val_loss: 0.2773 - val_accuracy: 0.9493\n",
            "Epoch 3/50\n",
            "119/119 [==============================] - 2404s 20s/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.1853 - val_accuracy: 0.9595\n",
            "Epoch 4/50\n",
            "119/119 [==============================] - 2370s 20s/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.1907 - val_accuracy: 0.9595\n",
            "Epoch 5/50\n",
            "119/119 [==============================] - 2311s 19s/step - loss: 0.0034 - accuracy: 0.9983 - val_loss: 0.1623 - val_accuracy: 0.9764\n",
            "Epoch 6/50\n",
            "119/119 [==============================] - 2232s 19s/step - loss: 2.6173e-04 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9730\n",
            "Epoch 7/50\n",
            " 10/119 [=>............................] - ETA: 26:24 - loss: 5.4711e-05 - accuracy: 1.0000"
          ]
        }
      ],
      "source": [
        "for train_index, val_index in kfold.split(merged_df):\n",
        "    print(f'Step {fold_no}: \\n')\n",
        "    fold_no += 1\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    train_data = merged_df.iloc[train_index]\n",
        "    val_data = merged_df.iloc[val_index]\n",
        "\n",
        "    # Create data generators for training and validation\n",
        "    train_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        x_col=\"img\",\n",
        "        y_col=\"status\",\n",
        "        color_mode='rgb',\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batchSize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        seed=123\n",
        "    )\n",
        "\n",
        "    val_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=val_data,\n",
        "        x_col=\"img\",\n",
        "        y_col=\"status\",\n",
        "        color_mode='rgb',\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batchSize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True,\n",
        "        seed=123\n",
        "    )\n",
        "\n",
        "    # Model creation\n",
        "    base_model = VGG19(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = layers.Flatten()(base_model.output)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dense(len(Labels), activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(base_model.input, x)\n",
        "\n",
        "    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
        "\n",
        "    epochs = 50\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=epochs,\n",
        "        callbacks=[callback]\n",
        "    )\n",
        "\n",
        "    epochsK.append(len(history.history['loss']))\n",
        "    train_loss.append(history.history['loss'])\n",
        "    val_loss.append(history.history['val_loss'])\n",
        "\n",
        "    print(\"___________________________________________________________________________\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "DfCdNvVqVHsJ",
        "outputId": "8ab4ecb7-042b-45bc-c7c8-5ce72b5b1083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.20414902 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.        ] [0.20414902 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.        ]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1aec21e74abd>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Kayıp grafiğini çizme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochsK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochsK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (45,) and (9,)"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Ortalama eğitim ve doğrulama kayıplarını hesaplama\n",
        "avg_train_loss = np.mean(train_loss, axis=0)\n",
        "avg_val_loss = np.mean(val_loss, axis=0)\n",
        "print(avg_train_loss,avg_train_loss)\n",
        "\n",
        "# Kayıp grafiğini çizme\n",
        "plt.plot(range(1, sum(epochsK)+1), avg_train_loss, label='Training Loss')\n",
        "plt.plot(range(1, sum(epochsK)+1), avg_val_loss, label='Validation Loss')\n",
        "plt.title('Cross Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO38TSVjXd4_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMFwzbHCXeLo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "SV1E2xtqXeOA",
        "outputId": "0966e601-8a10-463e-8eed-bbaab173f6af"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1a52c3479100>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert train_ds to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-1a52c3479100>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert train_ds to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             img = image_utils.load_img(\n\u001b[0m\u001b[1;32m    371\u001b[0m                 \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         raise TypeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Convert train_ds to numpy arrays\n",
        "train_images = np.array([image for image, _ in train_ds])\n",
        "train_labels = np.array([label for _, label in train_ds])\n",
        "\n",
        "# Extract the image paths from val_ds and test_ds\n",
        "val_paths = val_ds.filepaths\n",
        "test_paths = test_ds.filepaths\n",
        "\n",
        "# Extract the labels from val_ds and test_ds\n",
        "val_labels = val_ds.labels\n",
        "test_labels = test_ds.labels\n",
        "\n",
        "# Combine val_paths and val_labels into a list of tuples\n",
        "val_data = list(zip(val_paths, val_labels))\n",
        "\n",
        "# Combine test_paths and test_labels into a list of tuples\n",
        "test_data = list(zip(test_paths, test_labels))\n",
        "\n",
        "# Define the number of folds\n",
        "k = 5\n",
        "\n",
        "train_labels_int = np.argmax(train_labels, axis=1)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(train_images, train_labels_int)):\n",
        "    print(f'Fold: {fold + 1}')\n",
        "\n",
        "    # Split the training data into training and validation sets\n",
        "    fold_train_images, fold_train_labels = train_images[train_index], train_labels[train_index]\n",
        "    fold_val_images, fold_val_labels = train_images[val_index], train_labels[val_index]\n",
        "\n",
        "    # Create tf.data.Dataset for the fold\n",
        "    fold_train_ds = tf.data.Dataset.from_tensor_slices((fold_train_images, fold_train_labels))\n",
        "    fold_val_ds = tf.data.Dataset.from_tensor_slices((fold_val_images, fold_val_labels))\n",
        "\n",
        "    # print(fold_val_labels)\n",
        "    # plt.imshow(fold_train_images[0])  # Use 'gray' colormap for grayscale images\n",
        "    # plt.axis('off')  # Turn off the axes\n",
        "    # plt.show()\n",
        "\n",
        "    IMG_SIZE = (180, 180)\n",
        "    img_height = 180\n",
        "    img_width = 180\n",
        "\n",
        "    model = models.Sequential([\n",
        "        resize_and_rescale,\n",
        "        data_augmentation,\n",
        "        layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "        layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Create a new directory for the current fold\n",
        "    fold_dir = os.path.join(data_dir, f'fold_{fold + 1}')\n",
        "    os.makedirs(fold_dir, exist_ok=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        fold_train_ds,\n",
        "        validation_data=fold_val_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=[callback]\n",
        "    )\n",
        "\n",
        "    epochsK.append(len(history.history['loss']))\n",
        "    train_loss.append(history.history['loss'])\n",
        "    val_loss.append(history.history['val_loss'])\n",
        "\n",
        "    print(\"___________________________________________________________________________\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB3aH7upT4kZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj0lMjgjT4lf"
      },
      "source": [
        "# deneme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "PeKU_I0Qjn_-",
        "outputId": "1397f9b3-30b1-4010-fd4c-495ba6e7ee0f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03d3e871d825>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert train_ds to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Convert train_ds to numpy arrays\n",
        "train_images = np.array([image for image, _ in train_ds])\n",
        "train_labels = np.array([label for _, label in train_ds])\n",
        "\n",
        "# Extract the image paths from val_ds and test_ds\n",
        "val_paths = val_ds.filepaths\n",
        "test_paths = test_ds.filepaths\n",
        "\n",
        "# Extract the labels from val_ds and test_ds\n",
        "val_labels = val_ds.labels\n",
        "test_labels = test_ds.labels\n",
        "\n",
        "# Combine val_paths and val_labels into a list of tuples\n",
        "val_data = list(zip(val_paths, val_labels))\n",
        "\n",
        "# Combine test_paths and test_labels into a list of tuples\n",
        "test_data = list(zip(test_paths, test_labels))\n",
        "\n",
        "# Define the number of folds\n",
        "k = 5\n",
        "\n",
        "train_labels_int = np.argmax(train_labels, axis=1)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=123)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(train_images, train_labels_int)):\n",
        "    print(f'Fold: {fold + 1}')\n",
        "\n",
        "    # Split the training data into training and validation sets\n",
        "    fold_train_images, fold_train_labels = train_images[train_index], train_labels[train_index]\n",
        "    fold_val_images, fold_val_labels = train_images[val_index], train_labels[val_index]\n",
        "\n",
        "    # Create tf.data.Dataset for the fold\n",
        "    fold_train_ds = tf.data.Dataset.from_tensor_slices((fold_train_images, fold_train_labels))\n",
        "    fold_val_ds = tf.data.Dataset.from_tensor_slices((fold_val_images, fold_val_labels))\n",
        "\n",
        "    # print(fold_val_labels)\n",
        "    # plt.imshow(fold_train_images[0])  # Use 'gray' colormap for grayscale images\n",
        "    # plt.axis('off')  # Turn off the axes\n",
        "    # plt.show()\n",
        "\n",
        "    IMG_SIZE = (180, 180)\n",
        "    img_height = 180\n",
        "    img_width = 180\n",
        "\n",
        "    base_model = VGG19(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = layers.Flatten()(base_model.output)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(base_model.input, x)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                patience=20,min_delta=0,\n",
        "                                                restore_best_weights=True)\n",
        "\n",
        "    # Create a new directory for the current fold\n",
        "    fold_dir = os.path.join(data_dir, f'fold_{fold + 1}')\n",
        "    os.makedirs(fold_dir, exist_ok=True)\n",
        "\n",
        "    # Train the model\n",
        "    epochs = 100\n",
        "\n",
        "    history = model.fit(\n",
        "      fold_train_images, fold_val_images,\n",
        "      validation_data=(fold_val_images, fold_val_labels),\n",
        "      epochs=epochs,\n",
        "      callbacks=callback\n",
        "    )\n",
        "\n",
        "    epochsK.append(len(history.history['loss']))\n",
        "    train_loss.append(history.history['loss'])\n",
        "    val_loss.append(history.history['val_loss'])\n",
        "\n",
        "    print(\"___________________________________________________________________________\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}